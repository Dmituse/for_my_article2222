import numpy as np

class DecisionTree:
    def __init__(self, max_depth=None):
        self.max_depth = max_depth
    
    def fit(self, X, y):
        self.tree = self._build_tree(X, y)
    
    def _build_tree(self, X, y, depth=0):
        # Проверка условий остановки
        if depth == self.max_depth or len(np.unique(y)) == 1:
            return {'class': np.bincount(y).argmax()}
        
        # Выбор лучшего разделения
        best_feature, best_threshold = self._find_best_split(X, y)
        
        # Создание узла дерева
        node = {
            'feature': best_feature,
            'threshold': best_threshold
        }
        
        # Рекурсивное построение дерева для левого и правого поддерева
        left_indices = X[:, best_feature] < best_threshold
        right_indices = X[:, best_feature] >= best_threshold
        node['left'] = self._build_tree(X[left_indices], y[left_indices], depth + 1)
        node['right'] = self._build_tree(X[right_indices], y[right_indices], depth + 1)
        
        return node
    
    def _find_best_split(self, X, y):
        best_feature = None
        best_threshold = None
        best_gini = 1.0
        
        # Перебор всех признаков и порогов
        for feature in range(X.shape[1]):
            thresholds = np.unique(X[:, feature])
            for threshold in thresholds:
                # Вычисление Gini impurity для текущего разделения
                gini = self._gini_impurity(X[:, feature], y, threshold)
                
                # Обновление лучшего разделения, если необходимо
                if gini < best_gini:
                    best_gini = gini
                    best_feature = feature
                    best_threshold = threshold
        
        return best_feature, best_threshold
    
    def _gini_impurity(self, feature, y, threshold):
        # Вычисление Gini impurity для разделения
        left_indices = feature < threshold
        right_indices = feature >= threshold
        left_labels = y[left_indices]
        right_labels = y[right_indices]
        
        left_prob = np.sum(left_labels) / len(left_labels)
        right_prob = np.sum(right_labels) / len(right_labels)
        
        gini = 1.0 - (left_prob**2 + right_prob**2)
        
        return gini
    
    def predict(self, X):
        return np.array([self._classify(x, self.tree) for x in X])
    
    def _classify(self, x, node):
        if 'class' in node:
            return node['class']
        
        if x[node['feature']] < node['threshold']:
            return self._classify(x, node['left'])
        else:
            return self._classify(x, node['right'])


# Пример использования дерева решений для классификации файлов на вирусы

# Загрузка данных (X - признаки, y - метки классов)
X = np.array([[...], [...], ...])  # Заменить на реальные данные
y = np.array([...])  # Заменить на реальные метки

# Создание и обучение модели
tree = DecisionTree(max_depth=5)
tree.fit(X, y)

# Пример классификации новых файлов
new_files = np.array([[...], [...], ...])  # Заменить на новые файлы
predictions = tree.predict(new_files)
print(predictions)
